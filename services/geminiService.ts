import { GoogleGenAI } from "@google/genai";
import { GenerationConfig, EditConfig } from "../types";

const API_KEY = process.env.API_KEY || '';

// Initialize the client
const ai = new GoogleGenAI({ apiKey: API_KEY });

const MODEL_NAME = 'gemini-2.5-flash-image';

/**
 * Generates an image based on a text prompt.
 * Note: gemini-2.5-flash-image typically returns one image per request.
 * For multiple images, we will call this multiple times in the UI layer or Promise.all.
 */
export const generateImage = async (config: GenerationConfig): Promise<string> => {
  try {
    const response = await ai.models.generateContent({
      model: MODEL_NAME,
      contents: {
        parts: [{ text: config.prompt }]
      },
      config: {
        imageConfig: {
            aspectRatio: config.aspectRatio || "1:1"
        }
      }
    });

    return extractImageFromResponse(response);
  } catch (error) {
    console.error("Error generating image:", error);
    throw error;
  }
};

/**
 * Edits an image based on a source image and a text prompt.
 */
export const editImage = async (config: EditConfig): Promise<string> => {
  try {
    const response = await ai.models.generateContent({
      model: MODEL_NAME,
      contents: {
        parts: [
          {
            inlineData: {
              mimeType: config.sourceImageMimeType,
              data: config.sourceImageBase64
            }
          },
          { text: config.prompt }
        ]
      }
    });

    return extractImageFromResponse(response);
  } catch (error) {
    console.error("Error editing image:", error);
    throw error;
  }
};

// Helper to extract base64 image from the response structure
// The model can return text or image, we strictly look for inlineData
// eslint-disable-next-line @typescript-eslint/no-explicit-any
const extractImageFromResponse = (response: any): string => {
  const candidate = response.candidates?.[0];

  if (!candidate) {
    throw new Error("No candidates returned from Gemini.");
  }

  // Check if content is blocked or missing (handles 'Cannot read properties of undefined')
  if (!candidate.content) {
    if (candidate.finishReason) {
       // If blocked for safety or other reasons
       throw new Error(`Generation blocked. Reason: ${candidate.finishReason}`);
    }
    throw new Error("No content generated by the model.");
  }

  const parts = candidate.content.parts;
  
  // Safely check for parts
  if (!parts || parts.length === 0) {
    if (candidate.finishReason) {
       throw new Error(`Generation finished without content. Reason: ${candidate.finishReason}`);
    }
    throw new Error("The model returned an empty response.");
  }

  // Look for image data
  for (const part of parts) {
    if (part.inlineData) {
      return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    }
  }

  // If no image found, check if there is text explaining why (e.g. "I cannot generate...")
  const textPart = parts.find((p: any) => p.text);
  if (textPart) {
      // Return the text as the error message so the user knows why
      throw new Error(`Model message: ${textPart.text}`);
  }

  throw new Error("No image data found in response.");
};